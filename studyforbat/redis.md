## Redis

#### 使用场景
- string 自增（incre）、分布式锁（setnx）、seesion共享、
- hash  购物车 过期功能不能用在field上，只能用在key上。集群规模不适合使用，会造成数据倾斜
- list 栈（lpush+lpop） 队列（lpush+rpop） 阻塞队列（lpush+brpop）
- set 抽奖用户、点赞、关注模型、电商商品筛选
- 有序集合 排行榜
#### 单线程的高性能
- 基于内存
- 执行命令单线程，持久化、快照等是多线程
- I/O多路复用
#### redis持久化
- 持久化：RDB
  - save同步，不消耗内存
  - bgsave异步（默认）,同时fork子线程利用写时复制技术将bgsave期间客户端的请求数据同时也写进rdb文件
  - 机器宕机会丢失数据
- 持久化AOF 
  - append 将修改命令写进AOF文件（先写入oscache，每隔一段时间fsync写磁盘）
  - fsync三种策略
    - 每次有命令追加AOF时就执行一次fsync，非常慢也非常安全
    - 每秒fsync，只会丢失一秒数据（默认）
    - 从不fsync，将操作交由操作系统处理。快，但不安全
- AOF重写（fork子线程）
  - 文件大小达到设置阈值
  - 自从上次重写后增长达到设置百分比时
- 同时开启
  - 恢复数据时优先使用AOF恢复，数据更全
- redis4.0 混合持久化
  - 默认关闭 
  - AOF重写时，不会单存将内存数据转换为命令写入AOF文件，而是将重写这一刻之前的内存做RDB快照处理，并且RDB快照  
  内容和增量AOF修改内存数据的命令存在一起，都写入AOF文件，新的文件一开始不叫appendonly.aof，重写完成后文件改名、  
  覆盖原有AOF文件，完成新旧文件的替换。于是机器重启的时候可以先加载RDB的内容，然后重放增量的AOF日志就可以完全取代  
  之前的AOF全量文件重放，重启效率提升
- 备份策略
  - 定时调度脚本，将AOF或者RDB文件备份到一个目录，保留最近48小时数据
  - 每天保留当天数据到一个目录，保留最近一个月
  - 每次复制备份的时候，把太旧的数据删除
  - 每天晚上将当前机器上的备份复制一份到其他机器或者云盘
#### 主从与哨兵
- 单节点内存配置一般小于10g,有局限
- 主从架构
![](/studyforbat/pic/master-slave.png)  
- 原理
  - 给master配置一个slave，无论是否第一次连上slave，都会向master发送一个PSYNC命令给master请求复制数据
  - master收到命令后在后台进行数据持久化通过bgsave生成rdb文件，持久化期间master会继续接收客户端的请求，并将这些  
  可能修改数据集的命令缓存在内存。
  - 持久化完成后将rdb数据集文件发给slave，slave将接收到的文件持久化生成rdb文件，然后加载到内存。然后master将缓存到内存的  
  命令发给slave
  - 当由于某些原因断开连接时，slave能自动重连master。如果master收到多个slave并发连接请求，只会进行一次持久化而不是一次  
  一个连接一次。最后把数据发给多个并发连接的slave
    ![](/studyforbat/pic/psync.png)  
- 断点续传2.8版本开始
  - master会在内存中创建一个复制数据用的缓存队列，缓存最近一段时间的数据，master和它所有的slave都维护了复制数据的offset和master  
  的进程id，因此短看来重连时会从记录的数据下标开始。如果master进程id没了或者节点数据下标太久已经不再master的缓存队列了，那么会进行一  
  次全量复制
    ![](/studyforbat/pic/续传.png)  
- 为了防止从节点过多，缓解主从复制风暴（多从节点从主节点复制数据，造成主节点压力过大），做如下架构  
  ![](/studyforbat/pic/multilevel.png)  
- 哨兵架构
  ![](/studyforbat/pic/sentinel-slave.png)
- 哨兵节点是特殊的redis服务，不提供读写功能，主要用来监控redis实例节点
- 客户端第一次通过哨兵找到redis主节点，后续直接访问主节点。当主节点发生变化时，哨兵节点会第一时间感知到并通知给客户端（客户端一般实现了  
订阅功能）
#### 集群
- 将所有数据划分为16384个slot，每个实例分配以部分slot。当客户端建立连接时，会将槽位信息缓存到本地。请求时利用crc16算法渠道hash值，然  
后对16384取模得到具体槽位
- 跳转重定位：当客户端像一个错误的实例节点发送请求时，该节点发现key所在槽位并不归自己管理。他互相客户端发送一个特殊的跳转指令携带目标节点的  
地址，客户端收到指令后会跳转到正确的节点并更新本地槽位缓存信息
- 节点间通信协议：gossip，
  - 维护集群的元数据（集群节点、主从角色、节点数量，、各节点共享的数据）有两种方式
    - 集中式元数据更新、读取时效性比较好，一旦数据变更会立刻更新到集中式的存储中，其他节点读取的时候立即就可以感知到。但是元数据的更新压力  
    都集中在一个地方，可能导致元数据的存储压力。很多中间件都会借用zookeeper做集中式存储元数据
    - gossip协议包含多种信息，ping、pong、meet、fail等。
      - 元数据的更新比较分散，不是集中在一个地方。更新请求会陆陆续续达到所有节点上。有一定的延迟，降低了压力。可能会导致一些操作滞后
- 选举：
  - slave发现自己的master变为fail
  - 将自己记录的currentEpoch+1并广播FAILOVER_AUTH_REQUEST 信息
  - 其他节点收到信息后，只有master能回复，判断合法性，并发送FAILOVER_AUTH_ACK。对每一个eporch只发送一次ack
  - 尝试failover的salve收到ack
  - 收到超过半的master的ack的slave成为新的master
  - slave广播pong消息通知其他节点
  - slave并不是一感知到fail就发起选举，而是有一定延迟。从master复制的数据越新，延迟的时间越短，保证持有最新数据的slave首先发起选举
- 哨兵选举：也是过半原则
#### lua脚本&管道
- 管道：批量操作，不是原子的。一个明星失败不会影响其他命令的执行
- lua
  - 减少网络开销：五次网络请求可以用一个请求完成
  - 原子操作，一个脚本作为一个整体执行，中间不会有别的命令插入。
  - 替代redis的事务功能
  - 不要lua脚本中出现死循环和耗时的操作，否则会造成redis阻塞
####数据结构
- string sds 只扩不减  key过多时会引发rehash
  - 二进制安全
  - 内存预分配,避免频繁的内存分配
    - len 现有字符串占用长度
    - free 空闲长度 当字符串变更长度不够用时，会将字节数组扩增到（len+所缺长度）*2
    - 当长度达到1M时，每次扩展1M
  - 兼容C语言函数库（自动添加\0） 
- 默认16个Db hash桶长度默认4 2倍扩容
- 先访问0，存在将整个hash桶搬到1，不存在访问1.
- bitmap：key offset value 2的32次方-1
  - offset即为value在bitmap中的位置，默认为0，当存储的数据offset不连续、且间隔较大时，会浪费空间。因为会按offset最大的那个  
  去申请空间
  - 日活（或操作）、连续登陆（与操作）
- list 采用双端链表和ziplist来作为底层实现  
- hash 当数据量比较少或者单个元素比较小时时，底层为ziplist；数据量大时为字典 
  - 不能对内层key设置过期时间  
  - 当zipliist元素个数查过512
  - 单个元素大小超过64byte
- set key为null的dict。
  - 当数据可用整形表示时，被编码为intset
  - hashtable，以下条件任意满足
    - 元素个数大于设置 
    - 元素无法用整型表示
- zset dict+skiplist 
  - 跳表：建立索引层 时间复杂度logn 空间换时间
  - 层高：随机算法，效果和二分法得到的层高差不多
- GEOhash经纬度编码

#### 缓存失效（击穿）、穿透、雪崩
- 击穿：大批量key失效，请求直达数据库。在以一个基本时间基础上+一个随机时间
- 穿透：缓存空对象
  - 自身业务代码逻辑问题请求直达数据库
  - 恶意攻击、爬虫造成大量空命中请求直达数据库
- 雪崩：缓存层支撑不住，或者由于大量请求bigkey导致缓存支撑并发量急剧下降。大量请求达到存储层，导致数据库宕机
  - 集群高可用哨兵或者集群
  - 限流熔断并降级
  - 提前演练
- 热点缓存key的重建优化
  - 分布式锁保证只有一个线程能重构
- 双写不一致
  - 加过期时间
  - 串行执行
  - 延时双删：删除后睡眠一段时间再删除一次
  - 分布式锁串行，redission读写锁
  - canal中间件监听binlog（引入中间件，增加了复杂性）
- 缓存适合读多写少，加入缓存提高性能，如果写多读多又容忍不了数据不一致，那就没必要用缓存，直接操作数据库。缓存是和对实时性、一致性  
要求不是太高的数据
- key设计
  - 可读性
  - 简洁性
  - 不含特殊字符
- value设计
  - 拒绝bigkey
    - 字符串：单个value大于10kb
    - 哈希、集合、列表、有序集合等：元素过多（超过5000）
    - 渐进删除：hscan、sscan、zscan等
    - 危害：
      - 导致redis阻塞（执行慢，阻塞其他客户端请求）
      - 网络拥塞：带宽有限，导致请求发不过去
    - bigkey过期删除：配置异步删除
- redis事务比较弱，使用lua脚本
- 删除策略
  - 被动：当读一个key时，key已经过期就会进行删除
  - 主动：由于被动删除无法保证冷数据被及时删除，所以redis会定期删除一批已过期的key
  - 当使用内存超过限制时，会触发主动清理策略
  - 主动清理策略
    - 针对设置了过期时间的key 
      - 在筛选时，针对有过期时间的key，优先删除过期早的key
      - 在设置了过期时间的key中随机删除
      - 使用lru策略：删除最近最少使用。以最近一次访问时间为准
      - lfu：最不经常使用。以次数为准
    - 针对所有key
      - 从所有key中随机选择
      - lru
      - lfu
    - 不处理
      - 不删除数据，内存不足时拒绝所有写入操作并返回错误信息
- 默认是异常，推荐lru，热点数据lfu。主从只有主节点能过期删除数据，然后把删除命令同步给从节点
- 布隆过滤器：不存在一定不存在，存在也可能不存在。
  - 一个大型数组和几个不一样的无偏hash函数
  - 适用于数据命中不高、数据相对稳定、实时性低（通常数据集较大）的应用场景
  - 不能删除